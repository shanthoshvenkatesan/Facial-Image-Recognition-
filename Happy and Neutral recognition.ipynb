{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=j-3vuBynnOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 101) PNG\n"
     ]
    }
   ],
   "source": [
    "#To load an image file in pyhton\n",
    "\n",
    "jpgfile = Image.open(\"my-image.png\")\n",
    "print( jpgfile.size, jpgfile.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"C:/Users/sandy/train\"\n",
    "CATEGORIES = [\"Happy\", \"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for category in CATEGORIES:\n",
    "    path= os.path.join(DATADIR, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "        plt.imshow(img_array, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        break\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 79  77  79 ...  73  77  77]\n",
      " [ 83  82  82 ...  74  81  77]\n",
      " [ 86  86  84 ...  74  79  78]\n",
      " ...\n",
      " [ 64  68  70 ...  63  77  60]\n",
      " [ 67  70  74 ...  47  67  77]\n",
      " [ 67  81  78 ... 122  71  67]]\n"
     ]
    }
   ],
   "source": [
    "print(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48)\n"
     ]
    }
   ],
   "source": [
    "print(img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing the image\n",
    "\n",
    "#IMG_SIZE = 50\n",
    "\n",
    "\n",
    "#new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "#plt.imshow(new_array, cmap = \"gray\")\n",
    "#plt.show()\n",
    "#print(new_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data\n",
    "training_data = []\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path= os.path.join(DATADIR, category)  #Path for the Happy, Neutral images\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array=cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "                training_data.append([img_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "create_training_data()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12220\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the data\n",
    "\n",
    "import random\n",
    "\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#checking the labels are shuffled using sample\n",
    "    \n",
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] #Feature\n",
    "y = [] #Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "img_array = 48\n",
    "\n",
    "#For reshapping \n",
    "X= np.array(X).reshape(-1, img_array, img_array, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Using pickle to save the data, also we can use numpy to save the data\n",
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"Y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X= pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 13],\n",
       "        [ 48],\n",
       "        [ 60],\n",
       "        ...,\n",
       "        [119],\n",
       "        [ 80],\n",
       "        [ 43]],\n",
       "\n",
       "       [[ 38],\n",
       "        [ 67],\n",
       "        [ 39],\n",
       "        ...,\n",
       "        [109],\n",
       "        [118],\n",
       "        [ 74]],\n",
       "\n",
       "       [[ 84],\n",
       "        [ 80],\n",
       "        [ 67],\n",
       "        ...,\n",
       "        [112],\n",
       "        [132],\n",
       "        [ 89]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255],\n",
       "        [255],\n",
       "        [255],\n",
       "        ...,\n",
       "        [ 37],\n",
       "        [183],\n",
       "        [199]],\n",
       "\n",
       "       [[255],\n",
       "        [255],\n",
       "        [255],\n",
       "        ...,\n",
       "        [ 81],\n",
       "        [213],\n",
       "        [197]],\n",
       "\n",
       "       [[254],\n",
       "        [255],\n",
       "        [255],\n",
       "        ...,\n",
       "        [151],\n",
       "        [199],\n",
       "        [193]]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 10998 samples, validate on 1222 samples\n",
      "Epoch 1/10\n",
      "10998/10998 [==============================] - 67s 6ms/sample - loss: 0.5766 - acc: 0.6952 - val_loss: 0.4555 - val_acc: 0.8069\n",
      "Epoch 2/10\n",
      "10998/10998 [==============================] - 66s 6ms/sample - loss: 0.4609 - acc: 0.7853 - val_loss: 0.4240 - val_acc: 0.8151\n",
      "Epoch 3/10\n",
      "10998/10998 [==============================] - 68s 6ms/sample - loss: 0.4149 - acc: 0.8088 - val_loss: 0.3907 - val_acc: 0.8273\n",
      "Epoch 4/10\n",
      "10998/10998 [==============================] - 74s 7ms/sample - loss: 0.3818 - acc: 0.8269 - val_loss: 0.3909 - val_acc: 0.8257\n",
      "Epoch 5/10\n",
      "10998/10998 [==============================] - 73s 7ms/sample - loss: 0.3569 - acc: 0.8365 - val_loss: 0.3631 - val_acc: 0.8314\n",
      "Epoch 6/10\n",
      "10998/10998 [==============================] - 70s 6ms/sample - loss: 0.3341 - acc: 0.8522 - val_loss: 0.3896 - val_acc: 0.8241\n",
      "Epoch 7/10\n",
      "10998/10998 [==============================] - 65s 6ms/sample - loss: 0.3174 - acc: 0.8593 - val_loss: 0.3638 - val_acc: 0.8396\n",
      "Epoch 8/10\n",
      "10998/10998 [==============================] - 70s 6ms/sample - loss: 0.3005 - acc: 0.8685 - val_loss: 0.4076 - val_acc: 0.8265\n",
      "Epoch 9/10\n",
      "10998/10998 [==============================] - 70s 6ms/sample - loss: 0.2810 - acc: 0.8766 - val_loss: 0.3906 - val_acc: 0.8208\n",
      "Epoch 10/10\n",
      "10998/10998 [==============================] - 74s 7ms/sample - loss: 0.2594 - acc: 0.8933 - val_loss: 0.3839 - val_acc: 0.8265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27d88371940>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name = \"smilemodel-{}\".format(int(time.time()))\n",
    "logdir= \"C:\\\\Users\\\\sandy\\\\train\\\\{}\".format(Name)\n",
    "tensorboard = TensorBoard(logdir)\n",
    "\n",
    "X = pickle.load( open(\"X.pickle\", \"rb\"))\n",
    "y = pickle.load( open(\"y.pickle\", \"rb\"))\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), input_shape= X.shape[1:])) #64 Convolution units, 3,3 is window size and shape\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), input_shape= X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "\n",
    "model.add(Flatten()) #THis converts our 3D feature maps to 1D feature\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", #we can use categorical for more than 2 labels\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X, y, batch_size= 32, epochs=10, validation_split=0.1, callbacks=[tensorboard]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('train.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysing models with Tensorboard\n",
    "\n",
    "#tensorboard --logdir=foo:\"C:\\Users\\sandy\\train\" in Anaconda prompt\n",
    "#connecting using the command to see the visualisation in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndense_layers = [0,1,2]\\nlayer_sizes = [32,64,128]\\nconv_layers = [1,2,3]\\n\\n\\nfor dense_layer in dense_layers:\\n    for layer_size in layer_sizes:\\n        for con_layer in conv_layers:\\n            Name = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layers, layer_sizes, dense_layers, int(time.time()))\\n            logdir= \"C:\\\\Users\\\\sandy\\\\train\\\\{}\".format(Name)\\n            tensorboard = TensorBoard(logdir)\\n            print(Name)\\n            model = Sequential()\\n\\n            model.add(Conv2D(layer_size, (3,3), input_shape= X.shape[1:])) #64 Convolution units, 3,3 is window size and shape\\n            model.add(Activation(\"relu\"))\\n            model.add(MaxPooling2D(pool_size=(2,2)))\\n                \\n            for l in range(con_layer-1):\\n                model.add(Conv2D(layer_size, (3,3), input_shape= X.shape[1:]))\\n                model.add(Activation(\"relu\"))\\n                model.add(MaxPooling2D(pool_size=(2,2)))\\n    \\n\\n            model.add(Flatten()) #THis converts our 3D feature maps to 1D feature\\n\\n            for l in range(dense_layer):\\n                model.add(Dense(layer_size))\\n                model.add(Activation(\"relu\"))\\n                model.add(Dropout(0.2))\\n            \\n\\n            model.add(Dense(1))\\n            model.add(Activation(\"sigmoid\"))\\n\\n            model.compile(loss=\"binary_crossentropy\", #we can use categorical for more than 2 labels\\n            optimizer=\"adam\",\\n            metrics=[\"accuracy\"])\\n\\n            model.fit(X, y, batch_size= 32, epochs=20, validation_split=0.1, callbacks=[tensorboard]) \\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optimisation with Tensorboard\n",
    "\n",
    "dense_layers = [0,1,2]\n",
    "layer_sizes = [32,64,128]\n",
    "conv_layers = [1,2,3]\n",
    "\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for con_layer in conv_layers:\n",
    "            Name = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layers, layer_sizes, dense_layers, int(time.time()))\n",
    "            logdir= \"C:\\\\Users\\\\sandy\\\\train\\\\{}\".format(Name)\n",
    "            tensorboard = TensorBoard(logdir)\n",
    "            print(Name)\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3,3), input_shape= X.shape[1:])) #64 Convolution units, 3,3 is window size and shape\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                \n",
    "            for l in range(con_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3,3), input_shape= X.shape[1:]))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "\n",
    "            model.add(Flatten()) #THis converts our 3D feature maps to 1D feature\n",
    "\n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(Dropout(0.2))\n",
    "            \n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "            model.compile(loss=\"binary_crossentropy\", #we can use categorical for more than 2 labels\n",
    "            optimizer=\"adam\",\n",
    "            metrics=[\"accuracy\"])\n",
    "\n",
    "            model.fit(X, y, batch_size= 32, epochs=20, validation_split=0.1, callbacks=[tensorboard]) \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "[[0.]]\n",
      "Happy\n"
     ]
    }
   ],
   "source": [
    "#prediction\n",
    "CATEGORIES = [\"Happy\", \"Neutral\"]\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 48\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "model1 = tf.keras.models.load_model(\"train.model\")\n",
    "\n",
    "prediction = model1.predict([prepare(\"SandyAngry.jpg\")])\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "prediction = model.predict([prepare(\"SandyAngry.jpg\")])\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare(\"Sundarsmile.jpg\")])\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare(\"Sundarsmile.jpg\")])\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare(\"my-image.png\")])\n",
    "print(CATEGORIES[int(prediction[0][0])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
